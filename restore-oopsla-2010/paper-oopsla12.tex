\documentclass[natbib,10pt]{sigplanconf}

% \usepackage{dingbat}
\usepackage{threeparttable}
\usepackage{balance}
\usepackage{pifont}
\usepackage{booktabs}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mathptmx}
\usepackage[scaled=.92]{helvet} % see www.ctan.org/get/macros/latex/required/psnfss/psnfss2e.pdf
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{listings}
%\usepackage{highlighter}

\lstset{language=Java,basicstyle=\small\sffamily,otherkeywords={abort},columns=flexible,numberstyle=\em\scriptsize,frame=none,mathescape=true,escapechar={|},escapeinside={/**}{*/}}
\newcommand{\code}[1]{\lstinline|#1|\xspace}
\newcommand{\javac}{javac\xspace} % This package lets you punctuate \javac normally and get good spacing, e.g., \javac.  gives you: javac.
\usepackage{url}  % particularly useful for URLs in bib entries
\input{smagill-base}

\newcommand{\TOSAcronym}{\emph{Targeted Object Synthesis} (TOS)\xspace} 
\newcommand{\TOS}{TOS\xspace} 

\newcommand{\bh}{}%{\HighlightFrom}
\newcommand{\eh}{}%{\HighlightTo}

\newcommand{\stephen}[1]{\textcolor{Red}{Stephen: #1}}
\newcommand{\sbm}[1]{\textcolor{Red}{Stephen: #1}}
\newcommand{\suriya}[1]{\textcolor{blue}{Suriya: #1}}
\newcommand{\kathryn}[1]{\textcolor{blue}{Kathryn: #1}}
\newcommand{\mwh}[1]{\textcolor{blue}{Mike: #1}}
\newcommand{\todo}[1]{\textcolor{red}{#1}}

\begin{document}

\conferenceinfo{OOPSLA'12,} {October 19--26, 2012, Tucson, Arizona, USA.}
\CopyrightYear{2012}
\copyrightdata{978-1-4503-1561-6/12/10}

\title{Automating Object Transformations for Dynamic Software Updating
%   \thanks{COMMENT OUT FOR SUBMISSION, UNCOMMENT FOR final version. Some of these may or may not apply to your work.  Make Kathryn check.
%     This work is supported by NSF SHF-0910818, NSF CSR-0917191, NSF
%     CCF-0811524, NSF CNS-0719966, NSF CCF-0429859, Intel, IBM, CISCO,
%     Google, and Microsoft.  Any opinions, findings and conclusions
%     expressed herein are the authors' and do not necessarily reflect
%     those of the sponsors.}
    }

% 2008: NSF EIA-0303609, DARPA F33615-03-C-4106,


%\authorinfo{Anonymous}{}{}
 \authorinfo{Stephen Magill\thanks{Most of the work was completed
     while this author was at the University of Maryland, College Park.}}
            {IDA Center for Computing Sciences}
            {sbmagil@super.org}

 \authorinfo{Michael Hicks}
            {University of Maryland, College Park}
            {mwh@cs.umd.edu}

 \authorinfo{Suriya Subramanian}
            {Intel Corporation}
            {suriya@alumni.cs.utexas.edu}

 \authorinfo{Kathryn S. McKinley}
            {Microsoft Research \& The University of Texas at Austin}
            {mckinley@cs.utexas.edu}

\maketitle

\begin{abstract}
  Dynamic software updating (DSU) systems eliminate costly downtime by
  dynamically fixing bugs and adding features to executing programs.
  Given a static \emph{code} patch, most DSU systems construct runtime
  code changes automatically.  However, a dynamic update must also
  specify how to change the running program's execution \emph{state},
  e.g., the stack and heap, to make it compatible with the new code.
  Constructing such \emph{state transformations} correctly and
  automatically remains an open problem.  This paper presents a
  solution called \TOSAcronym.  \TOS first executes the same tests on
  the old and new program versions separately, observing the program
  heap state at a few corresponding points.  Given two corresponding
  heap states, \TOS  % we are going to use "key" in a perscribed way,
                     % so we need to not use it generically in nearby sentences.
  \emph{matches} objects in the two versions using \emph{key} fields
  that uniquely identify objects and correlate old and new-version
  objects. Given example object pairs, \TOS then \emph{synthesizes} the simplest-possible 
  function that transforms an old-version object to its new-version
  counterpart. We show
  that \TOS  is effective on updates to four open-source server
  programs for which it generates non-trivial transformation functions that use conditionals,
  operate on collections, and fix memory leaks. These transformations help programmers
  understand their changes and apply dynamic software updates.

\end{abstract}

\category{D.1.2}{Programming Techniques}{Automatic Programming}
\category{I.2.2}{Artificial Intelligence}{Program Synthesis}

\terms Algorithms, Languages, Theory

\keywords Dynamic Software Update, DSU, Hot-Swapping, Program Synthesis, State Transformation, Object Correlation, Object Matching

% {\scriptsize
% \category{D.3.4}{Programming Languages}{Processors}[Memory management (garbage collection); Optimization] 
% \terms
% Experimentation, Languages, Performance, Measurement
% \keywords
% Heap
% }

\input{defs.tex}

% \stephencomment{K; Fixed. TODO: unify notation.  We are currently using $o$ and $n$ in some places for old/new object, whereas in others we use $o$ and $o'$.  Also $o_1$ and $o_2$ pop up sometimes.}
\section{Introduction}

Suppose you are running an on-line service and a memory leak in your
server software causes it to regularly run out of memory and
crash.  Eventually you discover the one-line fix: the
\code{Connection} class's \code{close} method should
unlink some metadata when a connection closes.  To apply this
fix in a standard deployment, you stop your server and restart
the patched version, but this disrupts active users.  With 
\emph{dynamic software updating} (DSU) support in an extended Virtual Machine
such as LiveRebel~\cite{javarebel} you
can do better. You apply a \emph{dynamic} patch 
to the \code{Connection} class of your \emph{running}
system to prevent further leaks without disrupting current users.
In some DSU-enhanced VMs, such as Jvolve~\cite{jvolve}, you can do better
still. You include \emph{state 
  transformation} code in the dynamic patch that traverses the
heap and unlinks the useless metadata left reachable by the bug.

% Prior work shows how to implement code and
% data updates with special compilation support~\cite{update-streaks},
% run-time binary rewriting~\cite{}, and extended virtual machine (VM)
% functionality~\cite{jvolve}.    They further demonstrate successful
% application of years' worth of changes to applications and servers,
% such as the OpenSSH daemon, Very Secure FTP daemon (vsftpd), and
% memcached, to running systems to bring them up to date, even when they
% are actively performing work~\cite{jvolve,update-streaks}.

An important goal toward furthering the adoption of DSU systems is to
make them easy to use, i.e., to minimize the effort required to
produce a correct dynamic patch from two versions of a system.  As a
step in this direction, many DSU systems employ simple
\emph{syntactic}, \emph{type-based} tool support for constructing a
dynamic patch from the old and new program
versions~\cite{jvolve,ksplice,neamtiu06dsu, HicksNettles03}.  For
example, if the bytecode for method \code{m} of class \code{C} changes, Jvolve
will include \code{C.m} in the dynamic patch.  If \code{C}'s field
definitions change, in type or number, Jvolve creates a default
\emph{object transformation function} that it  applies to all
\code{C} objects when it applies the patch. This function retains
the values of unchanged fields and initializes the rest with a default
value, e.g., \code{null}.

While tool support for identifying changed code is highly effective,
existing support for constructing state transformation code is rarely
sufficient, and the programmer must therefore modify the generated code.  
For example, in Jvolve the programmer must  add code that
unlinks the leaked metadata in our example.  Unfortunately, the cases
that require manual intervention are often challenging to get right.
For the above example, the \code{Connection} transformer cannot simply unlink all
connection metadata unconditionally. Instead, it must use appropriate
context by examining the running program's heap and stack to
identify and unlink only the metadata that is logically dead.
Transformations that move objects between collections or
partition single objects into several objects---examples we 
observe in practice---require similar care in their construction.
Thus, writing state transformation code for DSU systems is a  programming task unique to DSU, and it can be
a time-consuming, error-prone process.

To ease this burden on programmers, we have developed a 
general-purpose approach for synthesizing object
transformers that we call \emph{Targeted Object Synthesis} (\TOS).
Our development is in the context of a DSU system for
Java, called Jvolve, but our techniques are readily adaptable to other
DSU systems. Furthermore, the
techniques that we design for finding heap object correlations between
different program versions may be useful for other program
understanding tasks, such as bug detection and testing.

% shows how to automatically synthesize object state
% transformers and thus in many cases, significantly reduce or eliminate
% developer effort due to DSU.  

\TOS works in two phases, \emph{matching} and \emph{synthesis}---the
matching phase creates examples by pairing objects in two snapshots taken at equivalent points during
the execution of the old and new programs, respectively, while the
synthesis phase generates a function that transforms the old object of
a matched example pair to the new object.

The matching phase begins by running both the old and new versions of the
program on the same inputs and taking heap snapshots at corresponding
program points.  Given a class \code{C} whose fields changed
between versions, we first reduce the heap snapshots such that they
only include \code{C} objects and objects to which they refer,
directly or transitively. \TOS matching seeks to correlate
objects in the old and new versions. \TOS identifies \emph{key fields}
in the objects that (1) uniquely identify the object in a given heap
(i.e., each object of class \code{C} differs on the values of its key
fields) and (2) there exist objects in both heaps with the same values
for these fields.  We use a greedy algorithm which, in our experience,
usually succeeds in finding a set of key fields.  In the case that
no key fields exist, matching uses the most distinguishing set of
fields it can find to pair up most objects, and then applies a
lightweight form of synthesis to find a function that
pairs up the remaining objects.

With example pairs of corresponding old $o$ and new $o'$ objects $(o,o')$ in hand, the
\emph{synthesis} phase searches for functions that are consistent with the
examples, i.e., functions $\delta$ for which $\delta(o) = o'$ for all
matched pairs.  Functions $\delta$ assign an expression to each
new-version object field one at a time, where the expressions may
reference any of the old object's fields (or fields reachable from
them).  These expressions may contain constants, simple functions
(e.g., the concatenation or partitioning of string expressions), and
conditionals (e.g., if the value to assign to a field depends on the
current value of another field). While these expression forms are
sufficient for our examples, additional expression forms can be
readily supported, expanding expressiveness at the cost of increasing the search
space.  For collections, we recursively
invoke synthesis to generate transformations between objects that make
up each collection, mapping the resulting function over the old
collection objects to produce the new one.  
When many functions are possible for a given set of
examples, synthesis chooses the simplest.  We
carefully designed the transformation language to make important
operations efficient, such as  intersecting a set of candidate functions.

As far as we are aware, the \TOS matching algorithm is new. No prior work attempts to 
map heap objects from unstructured heap snapshots of different program-version executions. The  
\TOS synthesis algorithm is inspired by recent work on synthesizing string
and Excel table data transformation functions from input and output
examples~\cite{Gulwani:popl:2011,Gulwani:pldi:2011}.  \TOS matching
creates examples \emph{automatically}, whereas this prior work requires
users to provide examples.  \TOS functions are a superset of string
transformations. Whereas Excel table functions focus on filters and numerics,
 \TOS data transformations focus on a more general problem, the transformation of heap objects.
% Repeat , and furthermore,
% \TOS generates the examples from unstructured heap snapshots.

% \TOS is similar to recent work on
% synthesizing string, Excel table, and code transformation functions
% from input and output
% examples~\cite{Gulwani:popl:2011,Gulwani:pldi:2011,MKM:11}.  Whereas
% this work requires users to specify the examples, \TOS generates
% them. \TOS also requires a richer
% transformation domain than prior work.  For example, object
% transformers are a superset of string transformations, and more
% general than table or code insertion and deletion functions.

We demonstrate our approach by synthesizing transformation functions
for updates to several open-source Java servers, including
JavaEmailServer (a POP and SMTP server), CrossFTP (an FTP server),
Azureus (a Bittorrent client), and JEdit (a graphical text
editor). In one case, changed objects do not have the key fields
that matching requires. In all the others, we show that \TOS
produces correct transformation functions. These functions include object field
additions, string partitioning, partitioning a collection based on a
predicate, and deleting objects due to memory leaks.  In fact, to our
knowledge no prior DSU system has considered the need
to correct the residual effects of bugs, such as a memory leak, and our synthesized
functions are the first demonstration of this capability.  \TOS
represents a substantial step toward realizing the promise of DSU
technology by reliably automating the most programmer-intensive step.
% of using a DSU system.

% In summary, this paper's contribution is \emph{Targeted Object
%   Synthesis}, a method for automatically generating data
% transformation functions needed by dynamic patches, which we 
% show is practical by considering a variety of real-world examples.

\section{Overview}
\label{sec:overview}

This section presents an overview of synthesizing state transformation
functions for dynamic software updates using \TOS.  We begin with some
background on DSU, present an example dynamic update taken from an
actual program change, and show how \TOS synthesizes this dynamic update
automatically.

\subsection{Dynamic software updating}

Suppose an old version of a program is actively running, and a new
version becomes available that fixes some bugs or adds some new
features.  In many cases, we would like to update the running program
without shutting it down since stopping it would degrade the user
experience or the program contains useful program state that is costly
to recreate. For example, users may have active connections or the program
may cache state, such as recent queries and network state.

To use a typical DSU system, we
must construct a \emph{dynamic patch}~\cite{HicksNettles03} that
specifies the changed code and a \emph{state transformation function},
which modifies heap objects and other program state, as necessary, to
work with the new code.  For example, if the old program version
maintains a list of \code{Connection} objects and the new version adds
some fields to the \code{Connection} class, the state transformation
function must initialize the values of the new fields for the existing
objects.  In some systems, the state transformer may also update the
\emph{control state} of the program, e.g., examining and modifying the
existing stack and program counter as necessary~\cite{upstare,jvolve}.
We implement \TOS for Jvolve~\cite{jvolve}, which performs DSU in a
Java Virtual Machine (Jikes RVM), but the \TOS design
generalizes to other DSU systems.

\begin{figure}
%\begin{wrapfigure}[13]{r}{2.5cm}
\begin{center}
\includegraphics[scale=0.55]{updated-program-trace}
% \begin{tikzpicture}
% [circ/.style={draw,circle,minimum size=0.3cm},
%  label distance=0.1cm,
%  node distance=0.65cm]
% \node[circ,label=left:\small Ver. 1] (a1) {};
% \node[circ,right=of a1] (a2) {};
% \node[circ,right=of a2] (a3) {};
% \node[circ,below=of a3,label=left:\small Ver. 2] (b3) {};
% \node[circ,right=of b3] (b4) {};
% \node[circ,right=of b4] (b5) {};
% \path (a1) edge[->,auto,swap] node {\small $a_1$} (a2);
% \path (a2) edge[->,auto,swap] node {\small $a_2$} (a3);
% \path (a3) edge[->,auto] node {\small $\delta$} (b3);
% \path (b3) edge[->,auto,swap] node {\small $a_3$} (b4);
% \path (b4) edge[->,auto,swap] node {\small $a_4$} (b5);
% \end{tikzpicture}
\end{center}
\caption{\label{fig:hybrid}Program trace at update point
  after a2.}
\end{figure}

Figure \ref{fig:hybrid} depicts a dynamically updated program's
execution.  The circles represent the program's state, the labels
$a_1, a_2, a_3, a_4$ represent \emph{actions}, e.g., messages sent to
and from client applications.  Each gray circle represents a state in
which a dynamic update is permitted---not every program state may be
amenable to certain dynamic updates, as discussed below.
In this trace, the program starts executing
at version 1, and after executing actions $a_1$ and $a_2$, it applies
a dynamic patch.  As a result, the code of the program is updated to
version 2, and the state transformation function $\delta$ is applied
to transform the current state.  A patch could have been applied in
the initial state or the one after $a_3$,  if a patch were
available at those times.

Most DSU systems work in three steps.  First, when a patch becomes
available and the program reaches an acceptable state, the DSU system dynamically loads
the new and changed code.  Second, it redirects existing references
to the new definitions.  Finally, it executes the state
transformation function to update the existing state.  Jvolve
implements these steps within a modified virtual machine. It uses
standard classloading to load new versions of classes.  For classes
whose only change is to the code of methods, Jvolve simply modifies
the metadata for that class to point to the new method definitions
(which the JIT may subsequently optimize).  For each class whose
objects' state requires modification (e.g., because the new version
adds fields), the patch must include an \emph{object transformation
  method}.  At update time, the garbage collector finds all objects
that require transformation. It executes the object transformation
method on each old object, creating and initializing a corresponding object that
conforms to the new class's type specification.

When a dynamic patch becomes available, the system may choose not to apply
it immediately.  A policy adopted by many DSU systems is to delay
updates while changed code is actually executing or referenced by the
call stack.  While this delay makes sense, it is not sufficient to
avoid trouble.  Hayden et al.~\cite{hayden11testing-journal} studied
several years' worth of changes to three server programs and found
that dynamic updates derived from actual releases sometimes fail even
while adhering to this ``activeness'' restriction.  Other
work~\cite{HicksNettles03}  suggests that simply asking
programmers to specify a few program points (dubbed \emph{update
  points}) at which updates are permitted makes the system easier to
reason about.  Hayden et al.'s study finds this approach to be
effective: updates were applied promptly (e.g., roughly every 10~ms)
and never failed.  Jvolve and several other
systems~\cite{neamtiu06dsu,HicksNettles03,upstare} support this
approach. \TOS uses update points to create correlated pairs of heap snapshots, as 
explained in Section~\ref{sec:matching-overview}.

\begin{figure}
\begin{lstlisting}
public class v131_User {
  private final String username, domain, password;
  private String[] forwardAddresses;
}
public class JvolveTransformers {
 ...
 public static void
  jvolveObject(User n, v131_User o) {
    n.username = o.username;
    n.domain = o.domain;
    n.password = o.password;
    int len = o.forwardAddresses.length;
    n.forwardAddresses = new EmailAddress[len];
    for (int i = 0; i < len; i++) {
      String[] parts = o.forwardAddresses[i].split("@");
      n.forwardAddresses[i] = new EmailAddress(parts[0], parts[1]);
}}}
\end{lstlisting}
\caption{\code{User} object transformer, JES 1.3.1--1.3.2 update}
\label{fig:example-xform}
\end{figure}

\begin{figure*}[t]
\centering
\begin{tabular}{c|c}
\begin{minipage}{2.8in}
\begin{lstlisting}[]
public class User {
  private final String username, domain, password;
  private String[] forwardAddresses;
  public User(...) {...}
  public String[] getForwardedAddresses() {...}
  public void setForwardedAddresses(String[] f) 
  {...}
}
public class ConfigurationManager {
  private User loadUser(...) {
     ...
     User user = new User(...);
     String[] f = ...;
     user.setForwardedAddresses(f);
     return user;
  }
}
$$
$$
$$
$$
$$
$$
$$
$$
$$
$$
$$
\end{lstlisting}
\end{minipage} &
\begin{minipage}{2.8in}
\begin{lstlisting}
public class User {
  private final String username, domain, password;
  private /**\bh*/EmailAddress/**\eh*/[] forwardAddresses;
  public User(...) {...}
  public /**\bh*/EmailAddress/**\eh*/[] getForwardedAddresses() {...}
  public void setForwardedAddresses(/**\bh*/EmailAddress/**\eh*/[] f) 
  {...}
}
public class ConfigurationManager {
  private User loadUser(...) {
     ...
     User user = new User(...);
     /**\bh*/EmailAddress/**\eh*/[] f = ...;
     user.setForwardedAddresses(f);
     return user;
  }
}
public class EmailAddress {
  public EmailAddress(String username, String domain) {
    _isEmpty = false;
    _username = username;
    _domain = domain;
  }
  ...
  private String _username = "";
  private String _domain = "";
  private boolean _isEmpty = true;
}   
\end{lstlisting}
\end{minipage} \\[1em]
(a) Version 1.3.1 &
(b) Version 1.3.2 \\
\end{tabular}
\caption{An update to JavaEmailServer (JES) \code{User} and
  \code{ConfigurationManager} classes}
\label{fig:email-example}
\end{figure*}

% to dramatically reduce the number
% of heap snapshots that must be considered during the matching phase.

\subsection{JavaEmailServer example}

We now present an example Jvolve dynamic
update and subsequently show how \TOS synthesizes it.
Figure~\ref{fig:email-example} illustrates code from versions
1.3.1 and 1.3.2. of JavaEmailServer (JES), a simple SMTP and POP e-mail
server, that we obtained from the JES open-source repository.  In the
old version of the \code{User} class, \code{forwardedAddresses} is an
array of strings.  In the new version, \code{forwardedAddresses} is an
array of \code{EmailAddress} objects.  This difference requires a
corresponding change to the types of other methods in the \code{User} class, and
to the \code{loadUser} method code of the \code{ConfigurationManager}
class, which sets the field by calling \code{setForwardedAddresses}.

A Jvolve dynamic patch for this update contains the new versions of
the \code{User} and \code{ConfigurationManager} classes.  No object
transformer is needed for the \code{ConfigurationManager} class
because only its methods have changed, not its fields.
Figure~\ref{fig:example-xform} illustrates the object transformer
method for \code{User} objects. The transformer is a \code{static}
method \code{jvolveObject} in the class \code{JvolveTransformers}.
The method takes the old-version object and an allocated uninitialized
new-version object as arguments.  Both have the same class name. To
distinguish them, Jvolve renames the old object's class to
\code{v131_User}.  The transformation method copies the first three
fields from the old to the new version.\footnote{Jvolve relaxes the Java language
  restrictions on private field accesses during an update.}  The
object transformer  
allocates and populates an array of \code{EmailAddress} objects to
replace the existing array of \code{String} objects.

Given two program versions, Jvolve and other DSU systems automatically
construct the code portion of a dynamic patch by syntactically
comparing the old and new class files. However, 
generating the object transformer in Figure~\ref{fig:example-xform} is
well beyond the reach of current techniques.  Jvolve produces the
first three lines, but then inserts the line \code{n.forwardedAddresses
  = null}.  Ginseng~\cite{neamtiu06dsu}, POLUS~\cite{chen:icse07}, and
DLpop~\cite{HicksNettles03} do slightly better: they
generate the loop, but the loop body simply assigns each element to null.
%the statement \code{n.forwardedAddresses[i] = null}. 
%
\TOS generates the correct object transformer for JES in its entirety.


\subsection{Snapshot Collection}

\TOS infers object transformers based on example pairs of (old-version,
new-version) objects and uses the test cases already present in
a programs test suite to produce these examples.
It does this by executing each test case twice---once with the old version
and once with the new version of the code.  At every update point
encountered during execution, it records 
a \textit{heap snapshot}, which records types and field values for all live
objects.
Figure \ref{fig:run-both} depicts this process.
The shaded circles are the update points at which we take heap
snapshots.  Thus each version in the figure will produce three
snapshots and these will later be compared to find example pairs for synthesis.

Snapshot collection is generally straightforward once the programmer
marks the update
points (which is already required
for dynamic updating).  Even far-reaching, complex
changes to code can be accommodated since update points tend to be
close to the root of the control-flow graph, in code that is quite stable.  For
example, our JavaEmailServer code has an update point at the end of
the main processing loop for the thread that handles sending outgoing
messages.  If a test case involves sending specific messages at
specific intervals, then the same number of snapshots will be created
during each run.  Futhermore, these snapshots will correspond in the sense that
the lists of sent and pending messages will be the same.  Changes to
the send routine, or the details of
the protocol used to send messages, do not affect this
correspondence.  Only updates that alter the high-level message
processing semantics are problematic---for example,
if the server switched from sending all pending messages at once to a
model where message sends are spaced out (perhaps to implement a
rate-limited send).  Such changes require great care because an
existing invariant---that there are no pending messages when the
update point is reached---no longer holds in new program versions.
These updates are best left to the programmer, so we do not view the
failure of TOS to cope with them as a significant shortcoming.

\subsection{Matching}
\label{sec:matching-overview}

%% \TOS takes advantage of update points to
%% align new and old program executions and generates heap snapshots in
%% the old and new version at these points, as shown in
%% Figure~\ref{fig:run-both}. Compared to the general problem of aligning
%% two program executions and heap snapshots, these update points
%% dramatically reduce the number of heap snapshots on which \TOS
%% performs matching.

\begin{figure}
%\begin{wrapfigure}[13]{r}{2.5cm}
\begin{center}
\includegraphics[scale=0.55]{comparing-heaps-two-runs}
% \begin{tikzpicture}
% [circ/.style={draw,circle,minimum size=0.3cm},
%  label distance=0.1cm,
%  node distance=0.65cm]
% \node[circ,label=left:\small Ver. 1] (a1) {};
% \node[circ,right=of a1] (a2) {};
% \node[circ,right=of a2] (a3) {};
% \node[circ,below=of a1,label=left:\small Ver. 2] (b3) {};
% \node[circ,right=of b3] (b4) {};
% \node[circ,right=of b4] (b5) {};
% \path (a1) edge[->,auto,swap] node {\small $a_1$} (a2);
% \path (a2) edge[->,auto,swap] node {\small $a_2$} (a3);
% \path (a3) edge[<->,densely dashed,auto] node {\small compare} (b5);
% \path (b3) edge[->,auto,swap] node {\small $a_1$} (b4);
% \path (b4) edge[->,auto,swap] node {\small $a_2$} (b5);
% \end{tikzpicture}
\end{center}
\caption{\label{fig:run-both}Comparing old and new heaps at update points.}
%\end{wrapfigure}
%\end{figure}
\end{figure}

\TOS works in two steps, \emph{matching} and \emph{synthesis}.
Matching takes as input the snapshots produced by the test runs
and the class $C$ for which we want to generate an object transformer.
It then produces pairs of (old-version, new-version) objects that serve
as examples to guide synthesis.  Early in the matching process we also
prune each snapshot to include only $C$ objects and objects to which they
refer, directly or transitively. This
linear pass through the heap significantly reduces the input size to
\TOS matching.

In general, \TOS requires that (1)  the test input generate the same number of
snapshots when run using each program version; and (2)  the
$i^\text{th}$ snapshot for a given input will always contain the same
set of objects of class $C$; and (3)  the corresponding
snapshots have the same number of $C$ objects
(though the number of instances of other classes may differ).  Intuitively,
the program must behave deterministically with respect to the objects
in $C$, and the \emph{role} of those objects in the two versions
must be the same.  The JES example illustrates this
point.  The email server itself is non-deterministic.  Network events
and the order in which requests are processed vary from one run to
the next.  However the set of forwarded addresses behaves
deterministically since it is read from the same configuration file in
both versions and 
does not vary across runs.  For all our real-world applications and
test inputs, these requirements were met.
% We only perform snapshots at update points because we want to
% infer the relationship between old and new objects at the points at
% which the object transformers will ultimately be run, 

\begin{figure*}[t]
\begin{center}
\footnotesize{
\begin{tabular}{ p{2.7in} p{2in}  p{1.7in}} \\ \toprule
\multicolumn{3}{c}{\textsf{\textbf{Old Version Heap Objects JES Heap}}}\\
\textsf{\textbf{user[0]}} & \textsf{\textbf{user[1]}} & \textsf{\textbf{user[2]}} \\[-1.75em]
\begin{lstlisting}
john
yahoo.com
poorpassword
["john@cs.umd.edu", "john-alice@yahoo.com"]
\end{lstlisting}
& 
\begin{lstlisting}
alice
yahoo.com
poorpassword
["john-alice@yahoo.com"]
\end{lstlisting}
&
\begin{lstlisting}
pat
intel.com
poorpassword
NULL
\end{lstlisting} \\[-1.5em] \midrule
\multicolumn{3}{c}{\textsf{\textbf{New Version Heap Objects JES Heap}}}\\
\textsf{\textbf{user[0]}} & \textsf{\textbf{user[1]}} & \textsf{\textbf{user[2]}} \\[-1.75em]
\begin{lstlisting}
john
yahoo.com
poorpassword
forwardedAddresses[0] = 
   [_username = "john", _domain = "cs.umd.edu"]
forwardedAddresses[1] = 
   [_username = "john-alice", _domain = "yahoo.com"]
\end{lstlisting}
&
\begin{lstlisting}
alice
yahoo.com
poorpassword
forwardedAddresses[0] = 
   [_username = "john-alice", 
    _domain = "yahoo.com"]
\end{lstlisting}
&
\begin{lstlisting}
pat
intel.com
poorpassword
NULL
\end{lstlisting} \\[-3em]
\end{tabular}}
\end{center}
\caption{JES heap example for \code{User} Class with fields, in order, \code{username, domain, password,} and \code{forwardedAddresses}.}
\label{fig:JES-heap}
\end{figure*}

The goal of the \emph{matching} phase is to produce a uniform
one-to-one mapping between objects in each pair of corresponding
snapshots.  It does this primarily by identifying a class's key
fields.  
\vspace*{1em}

\noindent \textbf{Definition} The fields $\vec{f}$ of a class $C$ are
\emph{key fields} if objects of class $C$ have two properties.
\vspace*{-1ex}
\begin{enumerate}
\item No pair of $C$ objects in the same snapshot have the same values
  for all the fields $\vec{f}$.
\item For each object in snapshot $\set_{old}$, there is exactly one
  object in the corresponding snapshot $\set_{new}$ that has the same
  values for fields $\vec{f}$.
\end{enumerate}

\noindent
As an example, Figure~\ref{fig:JES-heap} illustrates a snapshot pair
from JES with three objects of class \code{User} in the old (top) and
new (bottom) snapshots.  In this case, \TOS generates the mapping
$\{$(\code{user[0]$_{old},$}\code{user[0]$_{new}$}),
(\code{user[1]$_{old},$}\code{user[1]$_{new}$}),
(\code{user[2]$_{old},$}\code{user[2]$_{new}$})\} using key field
\code{username}.  This field is key because the values \code{john,
  alice}, and \code{pat} uniquely identify each object in both
$\set_{old}$ and $\set_{new}$ and there exists only one old and new
object with the same value. Neither \code{domain} nor \code{password}
are key fields because multiple objects in the same snapshot have the
same value.

If \code{user[2].username} was \code{john} instead of
\code{pat}, then there is no \emph{single} key field, since
none of the primitive fields \code{username}, \code{domain}, or
\code{password} have unique values.  In this case, matching searches
for a set of fields that all together satisfy the given
criteria. Given the modified \code{user[2]} snapshots, matching would find
that together the fields \code{username} and \code{domain} impose a
one-to-one mapping on all the objects.

If no set of key fields exists, our matching algorithm employs two
refinements, described in Section~\ref{sec:matching}.  First, it attempts to use referent object field values
as potential key fields.  If this attempt fails, it uses the set of key
fields/paths that is most discriminatory (i.e., it comes the closest
to producing a one-to-one matching), and then refines any objects not
yet matched by using a lightweight form of synthesis.

\subsection{Synthesis}

The matching phase ultimately produces a list of example pairs of
objects of a class $C$.  Synthesis then proceeds in roughly two steps.  (1) For
each example pair, the algorithm synthesizes a set of candidate functions.  (2) It
intersects the set of candidate functions to
produce a function consistent with all examples. In our implementation, the algorithm proceeds by synthesizing an initializer for each
field, one at a time.  The description given here, for simplicity,
presents the process as working for the entire transformer method at
once. % The actual approach is the same, just applied per field.

The first step proceeds as follows.  For each example  pair,
synthesis seeks a \emph{set} of functions $\Delta$ such that each
$\delta \in \Delta$ is consistent with the example, i.e., $o' =
\delta(o)$ for the example $(o,o')$.
Each $\delta_i \in \Delta$ assigns each new-version field one at a
time.   For example, consider the two \code{User} objects in
Figure~\ref{fig:JES-heap} that correspond to \textsf{user[0]}.  For
this example, synthesis will first infer $\delta_0$ that assigns the
\emph{constants} \code{john}, \code{yahoo.com}, and \code{poorpassword} to
each of the new object's fields \code{username}, \code{domain}, and
\code{password}, respectively. It also infers $\delta_1$ that \emph{copies} the
corresponding fields from the input object, i.e.,
\code{$\newvar$.username\ :=\ $\oldvar$.username},
\code{$\newvar$.domain\ :=\ $\oldvar$.domain}, etc.  For fields of type
\code{String}, it also considers assigning the concatenation of other strings,
e.g., those that are substrings of old-version fields.

For fields that are collections, we invoke synthesis recursively.  The
algorithm matches two
collections and then matches the set of objects in the two
collections. It then generates a transformation function between the
collection pairs from a transformation function for the object pairs.  For
\code{forwardedAddresses}, each \code{String} has the
form \code{"x@y"} and is mapped to an \code{EmailAddress} object
whose \code{username}, \code{domain}, and \code{_isEmpty} fields are
\code{"x"}, \code{"y"}, and \code{false}, respectively, where the
first two fields are substrings of the input string.  Once the
algorithm establishes an
element-wise function, it simply iterates over the old collection and
maps each element to one in the new collection.  
% If there are more
% objects in the old collection than the new one, we search for a
% conditional function that identifies the missing objects and filters
% them out.  If the collections have different sizes
% nondeterministically, we  take other steps, as described in
% Section~\ref{sec:synthesis}. \mwh{Is the previous statement relevant
%   anymore?  We can't do matching on snapshots with different
%   cardinality.} 

Once synthesis generates $\Delta$ for each pair of objects of class  $C$, it
intersects them to produce a $\hat{\Delta}$ that
is consistent with all the examples.  During this step, synthesis discards
overly-specific functions, e.g., it discovers that $\delta_1$
described above is consistent with 
all three of the matched pairs but $\delta_0$ is not, and
discards it.  If $|\hat{\Delta}| =
1$, then synthesis chooses $\delta \in \hat{\Delta}$ for the object transformer.  If
$|\hat{\Delta}| > 1$, it picks the $\delta \in \Delta$
that is intuitively the \emph{simplest} and \emph{most general}
function.  For example, we mark functions that contain assignments from old
fields to new fields as more general than functions that assign
constants.  If $|\hat{\Delta}| = 0$ then no one function
works for all examples.  In this case, synthesis picks the function that
works for the most examples and then iteratively seeks a function that
works for the remaining examples along with a conditional expression
that distinguishes between the two cases.

% \kathryn{Commented all this text out 11/2}
% \mwh{Stale text below; not sure if we want to show this function or
%   not, since we describe it above, and show it in Fig. 3 anyway}.

% The generated transformer would be \mwh{actually it's not, but it's
%   close to this}:

% \begin{align*}
% \lambda o.\ \lambda n.\ &n.\textsf{\_username} := \substr(o,0);\\ &n.\textsf{\_domain} := \substr(o,1);\\ &n.\textsf{\_isEmpty} := \textsf{false}
% \end{align*}

% \mwh{Not sure where the following text should go}
% Note that while the above discussion referring to executions of a
% program at different versions, we can record a similar sequence of
% corresponding snapshots for same-version executions.  We simply run
% version 1 twice starting from the same initial state and providing the
% same inputs.  Such \emph{v1-v1} snapshot sequences will be useful
% during our inference procedure.

\subsection{Discussion}

A key difference between \TOS and prior work on learning from examples
is that in prior work, the user identifies particular example pairs,
whereas in our work, the user must produce matching
\emph{executions}---created by running the old and new program
versions on the same inputs---from which \TOS automatically identifies
examples.  While automatic matching is simpler than
identifying example object pairs directly, there is a risk that it
will not pair up truly corresponding objects, in which case the
synthesized transformation function will be incorrect.  To reduce the
likelihood of this case, we place strong restrictions on the
inputs to matching, as described in the third paragraph of
Section~\ref{sec:matching-overview}: snapshots in both versions must
be taken at the same update points in both versions, there
must be an equal number of snapshots, and when synthesizing a
transformer for class $C$, there must be an equal number of $C$
objects in corresponding snapshots.  These restrictions ensure that
$C$ objects are playing the same role in the old and new execution, so
if we update the old program at one of these update points,
executing the synthesized transformer would bring the program to an
equivalent state.

Note that while corresponding snapshots must contain the same number
of $C$ objects, where $C$ is the changed class, the number of other objects can vary.  For
example, a buggy implementation of $C$ may fail to null its field $f$
of class $D$, inducing a memory leak.  Thus in the old and new
snapshots, the number of $C$ objects will be the same, but the number
of $D$ objects may differ.  As we show in our experiments, inferring
the transformer method for such a leaky class $C$ can end up
correcting the memory leak by nulling the dead objects.

Because \TOS generates a solution specific to the examples it is
given, the developer must snapshot executions that produce a
sufficient number of objects.  For conditional transformers, the input
must produce objects that cover the range of possible variations;
i.e., if there are $N$ conditions, \TOS needs at least an example pair for each
of the $N$ conditions.  These examples could come from a single snapshot with
$N$ instances of the object in both the old and new version or from
multiple snapshots which each contain one or two instances but
together provide $N$ examples.  If there are too few examples, then
synthesis may infer a function that is overly specific.

In our experience (described in
Section~\ref{sec:experiments}), it was easy to provide enough examples for
synthesis,
and most experiments required just one (well-chosen) test.  \TOS fails
in two of our test cases.  In one case we could not reproduce
a memory leak we were aiming to fix, leading to a failure during the
snapshot collection phase.  In the other case, the changed
objects did not have key fields and so the matching phase failed.  Despite these
limitations, our approach adds
value: the developer needs to run tests anyway, and if these tests are
sufficiently deterministic and cover the relevant behaviors of a
changed class, \TOS can be used to infer object transformers for that
class.

% Limitations:

% - Need to identify update points (required anyway)
% - Need to run testcases, and these need to produce an equal number of snapshots in the old and new versions that line up at equivalent program points. 
%   - You *don't* need tests for all code paths.  You need tests to produce a representative sample of the objects you want to synthesize between. For example, if you want to synthesize a memory leak fixing transformer, you have to run a test that exhibits the memory leak.  You also need to distinguish behaviors: e.g., if a field can vary, you want to show that, so we don't always infer the constant transformer.  If you fail to produce enough variety in the snapshots, you will synthesize overly specific transformers.  Don't care about code paths, but diversity of object instances.  Usually just a few instances suffice to express the needed diversity; for conditional transformers and there are N cases, you need N instances.
% - Equal number of C objects per snapshot, but possibly disequal number of referents from C objects, if using paths
%   - Synthesize transformers per field or field path.
%   - Need a bijection between objects to be convinced there is a transformer function

%   Nondeterminism is an open issue!  Need to control for it to make
%   sure we have the right input-output examples.  And there is still no
%   guarantee they are correct.  But intuitively this makes sense
%   because fields/roles don't change across versions.  Also, the more
%   objects you have, the more confidence you have they are correct.  If
%   you are somewhat familiar with the code, it should be easier to
%   verify the transformer is correct even if you couldn't generate it
%   yourself.


% \mwh{Should also clarify that a limitation is that update points need
%   to be reached in the same order in both executions; i.e., you can't
%   add an update point to the new version that wasn't there in the old
%   version or you might foul things up.}
% \mwh{More comments from reviewers that we could address here:}

% - The main weakness of the approach is that it relies on dynamic
% executions to exercise the modified code. Not only that, to obtain
% a sufficient number of examples for synthesis, the heap (probably)
% has to contain a sufficient number of modified objects. In general,
% this is hard to do, especially for server applications and large
% applications of the kind in which dynamic updates make most sense.

% - Another issue is the correctness guarantee of the technique. In
% [5] the user is involved in the spreadsheet transformation and can
% abort/refine in case it does not match his expectations. In
% contrast, for DSU, manual reasoning about the correct
% transformation is what we're trying to avoid.

% - What are the assumptions on the static code patch?

% - is it reasonable to assume that only a single class changes in an
% update or that there are no relationships between updated classes?
% Generalizing this assumption has significant impact on the
% complexity of matching (and synthesis) and in full generality may
% deteriorate to checking subgraph isomorphism.

% - is it reasonable to assume that every object in the old heap has
% a counterpart in the new heap?

% p.3: For matching you require that two runs of a program produce the same
% objects of a modified class C on the heap. This seems to imply that objects of
% class C cannot be allocated in different threads that might be active at the
% time of an update. Otherwise, the number of C objects at the time of the update
% depends on the scheduling. How do you find out if this restriction holds?

\section{Matching}
\label{sec:matching}

Now we present the \TOS matching algorithm in detail; the next section
describes the synthesis algorithm.  The goal of matching is to produce
example pairs $(o,o')$ of corresponding old and new objects taken from 
heap snapshot pairs.  The synthesis phase takes these pairs as input and
searches for a function $\delta$ such that $\delta(o) = o'$ for all
the example pairs.  The functions are  class based, thus all old
objects $o$ must have the same class $C$ and all new objects must
have the same class $C'$. We first assume $C = C'$, and then
consider $C \neq C'$, when matching recursively during
synthesis.

We describe our algorithm using the following notation.  A snapshot
$\set$ is just a set of objects; we use the two terms interchangeably.
We write $\vec{X}$ to denote a list of $X$s; $\vec{X}$
\code{::} $X$ to denote concatenating the element $X$ to the end of
the list $\vec{X}$; and $\vec{X}(i)$ to denote the $i^{th}$ element of
the list $\vec{X}$.  We sometimes refer to a list as a \emph{tuple} (e.g.,
when its length is known to be fixed).
We write $o.\vec{f}$ to denote the tuple $\vec{v}$
where $o.f_i = v_i$ for $0 < i \leq n$.  We write
$\values{\vec{f}}{\set}$ for the set of value tuples assigned to
fields $\vec{f}$ by objects in $\set$, i.e., $\values{\vec{f}}{\set} =
\{\vec{v} \mid o \in \set \wedge o.\vec{f} = \vec{v} \}$. Finally, we
write $\restrictval{\setlst}{\vec{f}}{\vec{v}}$ for $\{o \mid o \in
\set \wedge o.\vec{f} = \vec{v}\}$.

Figure~\ref{fig:matching-alg} gives the pseudocode for the matching
algorithm in the function called \code{match}.  
The input to \code{match} is a pair of lists of object sets
($\setlst_{old}$, $\setlst_{new}$).  The object set
$\setlst_{old}(i)$ contains objects collected from the $i^{th}$
snapshot taken while running the old program, while $\set' =
\setlst_{new}(i)$ contains objects collected from the corresponding
snapshot of a run of the new program.  

As mentioned earlier, we first \emph{prune}
the snapshots to include only objects of classes 
\code{C} that changed between the old and new version and
objects to which these objects directly or transitively refer.
We assume that this pruning has happened prior to the call to \code{match}.
We also assume that there are the same number of snapshots for the old and
new program executions ($\setsize{\setlst_{old}} =
\setsize{\setlst_{new}}$), and that each corresponding pruned snapshot has
the same number of objects ($\setsize{\setlst_{old}(i)} =
\setsize{\setlst_{new}(i)}$). 
If these conditions do not hold then matching fails for the class in question.
The \code{match} function returns a list of object pairs $(o,o')$, the
first from an old snapshot and the second from a new snapshot, which
serves as input for synthesis.

\begin{figure*}
\begin{tabbing}
\begin{minipage}{3.9in}
\begin{lstlisting}[numbers=left]
match($\setlst_{old}$, $\setlst_{new}$) =
  kfs := get_keyfields($\setlst_{old}$, $\setlst_{new}$) /**\label{line:getfields}*/
  ($\setlst'_{old}$, $\setlst'_{new}$) = split_on_keyfields(kfs,$\setlst_{old}$,$\setlst_{new}$) /**\label{line:split}*/
  if $\exists i.\ \setsize{\setlst'_{old}(i)} > 1$ then /**\label{line:singleton-check}*/
    $(\setlst'_{old},\setlst'_{new})$ := synthesis_match($\setlst'_{old}$, $\setlst'_{new}$) /**\label{line:match}*/
  return $\{ (o,o') \mid \exists i.\, 0 < i \leq
    \lstlength{\setlst'_{new}} \wedge
    o \in \setlst'_{old}(i) \wedge o' \in \setlst'_{new}(i) \}$
\end{lstlisting}

\begin{lstlisting}[numbers=left,firstnumber=last]
get_keyfields($\setlst_{old}$, $\setlst_{new}$) =
  kfs := []
  currscore := 0
  repeat {
    prevkfs := kfs;
    for each field $f \not\in$ kfs { /**\label{line:firstloop}*/
      kfs$'$ := kfs :: $f$
      $\textsf{score}(f) = 0$
      for each $i \in 1 .. \lstlength{\setlst_{new}}$ {  /**\label{line:innerloop}*/
        V := $\values{\mathsf{kfs'}}{\setlst_{old}(i)}$
        if $\forall \vec{v} \in $V$.\ \setsize{\restrictval{\set_{old}(i)}{\mathsf{kfs'}}{\vec{v}}} = \setsize{\restrictval{\set_{new}(i)}{\mathsf{kfs'}}{\vec{v}}}$ then /**\label{line:if-val}*/
          $\textsf{score}(f)$ := $\textsf{score}(f) + \setsize{$V$}$
        else {
          $\textsf{score}(f) = 0$
          break /**\label{line:break}*/
      } }
    }
    let $g$ be the $f$ that maximizes $\textsf{score}(f)$
    if $\textsf{score}(g)$ > currscore {
      kfs := kfs :: $g$
      currscore := $\textsf{score}(g)$
    }
  } until (prevkfs = kfs)
  return kfs
}
\end{lstlisting}
\end{minipage}
\=
\begin{minipage}{3.2in}
\begin{lstlisting}[numbers=left,firstnumber=last]
split_on_keyfields(kfs,$\setlst_{old}$,$\setlst_{new}$) =
  if kfs = [] then return $(\setlst_{old},\setlst_{new})$
  $\setlst'_{old}$ := []
  $\setlst'_{new}$ := []
  for each $i \in 1 .. \lstlength{\setlst_{new}}$ {
    for each $\vec{v} \in \values{\mathsf{kfs}}{\setlst_{old}(i) \cup \setlst_{new}(i)}$ {
      $\setlst'_{old}$ := $\setlst'_{old} \concat \restrictval{\set_{old}(i)}{\mathsf{kfs}}{\vec{v}}$
      $\setlst'_{new}$ := $\setlst'_{new} \concat \restrictval{\set_{new}(i)}{\mathsf{kfs}}{\vec{v}}$
    }
  }
  return $(\setlst_{old},\setlst_{new})$
\end{lstlisting}

\begin{lstlisting}[numbers=left,firstnumber=last]
synthesis_match($\setlst_{old}$,$\setlst_{new}$) =
  $\setlst_{old}'$ := []
  $\setlst_{new}'$ := []
  for each $k \in 1 .. \lstlength{\setlst_{old}}$ {
   $\sigma$ := $\setlst_{old}(k)$
   $\sigma'$ := $\setlst_{new}(k)$
   if $|\sigma| \not= 1 \vee |\sigma'| \not= 1$ then
    while $\sigma' \not= \emptyset$ {
      choose $o$ from $\sigma$ /**\label{line:choose}*/
      let $\updset$ = $\bigcup_{o_i \in \sigma'}$ synth_non_branching($o$,$o_i$) /**\label{line:synthmatch}*/
      letfun score($\delta$) = $\setsize{\sigma' \cap \delta(\sigma)}$ /**\label{line:scorefun} */
      let $\hat{\delta}$ be the element of $\Delta$ that maximizes score /**\label{line:maxscore} */
      let $\hat{U} = \{(o,o') \mid (o,o') \in \sigma \times \sigma' \wedge o' = \hat{\delta}(o)\}$
      for each $(o,o') \in \hat{U}$ { /**\label{line:loop}*/
        $\setlst_{old}'$ := $\setlst_{old}' \concat \{o\}$
        $\setlst_{new}'$ := $\setlst_{new}' \concat \{o'\}$
        $\sigma$ := $\sigma - \{o\} $
        $\sigma'$ := $\sigma' - \{o'\} $
     }
    }
  }
  return $(\setlst_{old}', \setlst_{new}')$
\end{lstlisting}
\end{minipage}
\end{tabbing}
\caption{\label{fig:matching-alg}Pseudocode for the \textsf{match} function.}
\end{figure*}

\subsection{Key fields}

The \code{match} function first calls \code{get_keyfields}
(line~\ref{line:getfields}) to search for key fields that partition
the objects in corresponding pruned snapshots.  Given a list of fields
\code{kfs}, and the old and new snapshots, \code{match} calls
the function \code{split_on_keyfields}, which returns a pair of object
set lists whose $i^{th}$ elements correspond.  In particular, each
object $o \in \setlst_{old}(i)$ and $o' \in \setlst_{new}(i)$ have the
same values for fields in \code{kfs}.  Ideally, the size of
$\setlst_{old}(i)$ and $\setlst_{new}(i)$ returned by
\code{split_on_keyfields} will be $1$ for all $i$.  In this case (as checked
on line~\ref{line:singleton-check}), each object is uniquely
identified by the fields \code{kfs} in every snapshot and there is a
corresponding object in the old (respectively, new) snapshot with the
same field values.  The size of a set will be greater than 1 if there
are multiple objects in a single snapshot that contain the same values
for fields in \code{kfs}.  If sets are non-singleton, \code{match}
uses lightweight synthesis to complete the partition.

The function \code{get_keyfields} iteratively adds new fields to the
list \code{kfs}. When it reaches a fixed point, it returns the list.
The first nested loop (line~\ref{line:firstloop}) considers each
possible relevant field $f$ for objects of class $\tau$.  The function
assigns each field a \emph{score} based on how well $f$, when added to
the current fields in \code{kfs'}, distinguishes the objects.  The
inner loop (line~\ref{line:innerloop}) considers each pair of
snapshots and computes the set \code{V}, which contains the distinct
tuples of \code{kfs'} fields' values in old-version objects.  Line \ref{line:if-val}
then considers each of the tuples $\vec{v}$ in set \code{V}.  It must be the case
that we have the same number of old and new objects with values
$\vec{v}$ in fields \code{kfs'}.  This requirement preserves the ability to discover a
bijection between the objects. The larger $\setsize{V}$ is,
the finer the partition induced by splitting on \code{kfs'}.  Synthesis
prefers finer partitions, which indicate more effective key fields.  Thus
\code{match} adds $\setsize{V}$ to \code{score} and then chooses the field that
maximizes \code{score}.  If a field $f$ leads to the condition
on line \ref{line:if-val} being violated, then \code{match} assigns $f$ a score of 0 and
proceeds to the next field.

Once it scores all the fields, \code{match} picks the
field $g$ that maximizes the score.  If the best score does better at
distinguishing objects than it previously did when using just fields
in \code{kfs}, it adds $g$ to \code{kfs} and continues iterating.

If \code{get$\_$fields} cannot find a bijection using one or more
primitive fields, we extend it by changing the first nested loop
(line~\ref{line:firstloop}) to consider \emph{field paths}. A field
path $\vec{f}$ is a list of fields, e.g. $f_1.f_2$.  The value given
by $o.\vec{f}$ is the value assigned to field $f_2$ in the object
referenced by $o.f_1$.  Beyond the replacement of $f$ with $\vec{f}$,
the algorithm in Figure \ref{fig:matching-alg} is unchanged.  If
matching with field paths still does not produce a bijection, we apply
synthesis-based matching, described in Section \ref{sec:synth-match}.

% MWH: we actually do this:
% Fig.6, function get\_keyfields: I had expected that you simply check if a
% specific field (or field combination) is unique in Sigma.old(i) and if for
% every key value in Sigma.old(i) there is a single object with this key value in
% Sigma.new(i). The implementation that you give seems to be more complicated.
% Why? Also, your algorithm does not seem to stop if a single field is identified
% to be sufficient as a key.

% \mwh{Somewhere point out that we use field paths, not fields, in this
%   algorithm.  Didn't want to say it here, because that's complicated.
%   Which paths?  How deep?  Would be better to keep it simple here and
%   just refer back from somewhere else that we take advantage of more
%   generality.} \kathryn{I think we can make it understandable.  See above.}

\subsection{The Old-Version Consistency Check}

Note that the description of matching thus far has not made use of the
fact that the objects in the two snapshot lists are the result of executing
different program versions.  We have described the
inputs to \code{match} as a list of old-version snapshots and a list
of new-version snapshots, but these could equally well be two lists of
old-version snapshots produced by separate runs of the old version
over a single test case.  Performing such an \textit{old-old} match is
useful as a preprocessing step prior to \textit{old-new} matching.

Recall that \code{get\_keyfields} assigns to each field $f$ a score,
given by \code{score($f$)}.  This score is non-zero if and only if
partitioning each snapshot on field $f$ produces sets with equal
cardinalities.  We use this property in old-new matching as a heuristic to find
fields that are unchanged by the update and that help pair up
corresponding objects.  We would also expect these fields to have
non-zero score in an old-old matching, and we use this additional 
check to ensure that we are in fact finding unchanged
fields.  In our implementation, we first perform an old-old matching
and consider only those fields $f$ with $\textsf{\small{score}}(f) {} > 0$ as
potential key fields for the old-new matching.

Old-old matching also helps focus synthesis.  If a field $f$
has score $0$ in the old-old case, then this field behaves
non-deterministically.  As an example, both time-stamps and nonces would have this
property.  We do not infer transformations for these fields
because even if we match objects correctly, the difference between the old
and new values for these fields will not solely be the result of the
code change.

Finally, if we fail to produce an old-old matching, then we can
say with certainty that this is not an object for which we should
perform \TOS.  We can also provide the programmer with
feedback indicating that the failure to synthesize is not due to the
code change's effect on the object, but rather due to inherent
problems with the role of the object in the given test case.
%  used during the
% snapshotting phase.

\subsection{Synthesis-based matching}
\label{sec:synth-match}

If key fields do not induce singleton sets, we
further decompose the non-singletons, since whenever $\setlst_{old}'(i)$ and
$\setlst_{new}'(i)$ contain more than one element each, it is 
unclear which pair $(o_1,o_2)$ with $o_1 \in \setlst_{old}'(i)$ and $o_2
\in \setlst_{new}'(i)$ to use as an input-output example for synthesis.
In this case, \code{match} calls
\code{synthesis_match} with the two current lists of
corresponding sets to refine the non-singleton sets in the
lists.

Synthesis-based matching tries to find a matching that is 
witnessed by a transformation function $\delta$ that maps objects in the
old set to objects in the new set.  We introduce additional
terminology to explain the algorithm.  We say that $\delta$ is
\emph{consistent} with the object pair $(o,o')$ iff $o' = \delta(o)$.
We call a set of pairs $U$ a \emph{matching} iff for all pairs
$(o_1,o_1')$ and $(o_2, o_2')$ in $U$, we have $o_1 \neq o_2
\Leftrightarrow o_1' \neq o_2'$.  That is, no old-version object is
paired with multiple new-version objects, nor is any new-version
object paired with multiple old-version objects.  
% When $U$ is a
% matching with elements in $\sigma \times \sigma'$, we write $\sigma
% \matching{U} \sigma'$.  Formally, $\delta$ is consistent with a
% matching $U$, written $U \subseteq \delta $, if and only if $\forall
% (o,o') \in U.\ o' = \delta(o)$.

The \code{synthesis_match} function iterates over each pair of
object sets, searching for a one-to-one matching between the old and new
objects of each when the sets $\sigma$ and $\sigma'$ are not
singletons.
Consider the non-singleton pair $\sigma$ and $\sigma'$. The algorithm
first chooses an old-version object $o$ (line~\ref{line:choose}).  It
may choose any object since it must eventually find transformation functions
for all objects in $\setlst_{old}$. It then considers each pair
$(o,o_i)$, where $o_i$ is a new-version object, with the aim of
synthesizing $\updset_i$, a \emph{set} of transformation functions consistent
with the example $(o,o_i)$. The algorithm combines all these sets of functions into a single
set of transformation functions $\updset$  (line~\ref{line:synthmatch}). The synthesis
procedure used here is restricted to non-branching transformation functions.
These are functions that do not perform case analysis on the
old-version object.  (Figure~\ref{fig:non-branch-synthesis} gives
pseudocode for this function, which is explained in the next section.)
Without this restriction, the inferred functions can always 
create a conditional function specific only to this one pair, but
these functions are not general and do not help create sets of
examples for synthesis of general functions.

Line~\ref{line:scorefun} defines a function \code{score} that scores possible
transformation functions $\delta$ in $\Delta$. The algorithm chooses
the highest-scoring
function $\hat{\delta}$ (line~\ref{line:maxscore}).  The
score of a transformation $\delta$ is determined by how well it maps
objects in $\set$ to those in $\set'$---in the figure we write
$\delta(\set)$ to mean $\{ o' \mid o \in \set \wedge o' = \delta(o)
\}$.  Thus a high-scoring function will map the input set to many
objects that match (intersect with) the output set.  The mapping
induced by $\hat{\delta}$ is given in $\hat{U}$.  
%% This is the same
%% approach we use when performing our post-matching synthesis phase.
Finally, the loop on line~\ref{line:loop} adds the singleton sets comprising this mapping to
$\setlst'_{old}$ and $\setlst'_{new}$ (which will be the ultimate
output of this function) and then removes the mapped elements from the
current snapshots $\sigma$ and $\sigma'$. The algorithm greedily
continues, iteratively choosing transformation functions that maximize
the number of example pairs they cover.  Once $\sigma$ becomes
empty, which is sure to happen because ultimately objects can be
matched arbitrarily using constant functions,
the while loop exits and synthesis moves on to the next snapshot, continuing
until it considers all pruned snapshots.

% \mwh{Claim: The matching process is quadratic in the number of fields.
%   Justify this claim here?}

% \mwh{Reviewer comment: Assume, an object of a modified class C references a D object with a field f,
% which has the value A in the old version and B in the new version. Does your
% matching find that out? This can proliferate, i.e. C references D, which
% references E, which has a field f that differs, etc.}

\section{Synthesis}
\label{sec:synthesis}

The synthesis phase takes the example pairs produced by matching and
synthesizes a function $\delta$ from them such that for the pair
$(o,o')$, $\delta(o) = o'$.

\subsection{Transformation functions $\delta$}

A transformation function $\delta$ is defined according to the grammar in
Figure~\ref{fig:language}.  Transformation functions take an old-version
object in $\oldvar$, allocate a new-version object in $\newvar$,
assign values to each of the fields of $\newvar$, and then return
$\newvar$.  Field assignments $g$ are of the form $\newvar.f := c$
where $c$ is a conditional and $f$ is a \emph{field path}---that is,
it is a (possibly empty) list of field labels $l$.  For $\newvar$, this
path is almost always a single field. (Section~\ref{sec:synth-discuss}
discusses the multiple fields case.)  Each conditional $c$
specifies one or more cases distinguished by boolean expressions $e_i$
over old-version state (i.e., they can only refer to objects via
$\oldvar$, never $\newvar$).  Each case has an initializer expression
$d$ which is either a constant, a reference to an old field, a string
produced by concatenating one or more (sub)strings, or a collection
produced by $\map$. Here, $\map(\delta,\oldvar.f)$ takes the collection at
$\oldvar.f$, and 
transforms these elements using $\delta$.  

The string expression
$\substr(\oldvar.f,i)$ splits the string $\oldvar.f$ at positions
where a delimiter $\mathit{delim}$ appears and then selects the
$i^\text{th}$ substring.
For example, $\substr(\text{"foo@bar.com"},2)$ returns
``bar.com'' since `@' is a delimiter that splits the string into two substrings
and ``bar.com'' is the second substring.  Our language of
string updates supports a concatenation of substrings and is
sufficient for the examples we considered.  If a more robust string
transformation language were needed, the approach taken by Gulwani
\cite{Gulwani:popl:2011,Gulwani:pldi:2011} or any other example-based
string synthesis technique would work easily.

%% Note that what we have defined is a language of \emph{class-based}
%% transformers.  That is, a separate update function $\delta$ is
%% defined for each class and applied independently to each object of
%% that class.  An alternative would be to transform the heap by walking
%% the entire object graph.

We have simplified the form of $\delta$ to keep the algorithm
tractable.  The most obvious restriction is that $\delta$ transforms a
single object, rather than multiple objects at once.  This restriction
derives from the nature of the underlying DSU system we use,
Jvolve.  Note that different objects of the same class will not
necessarily be transformed in the same way---conditionals $c$ may
evaluate to different branches for different objects and thereby
trigger different initializers.  Another restriction is that each
field of the new object is initialized independently, albeit with
access to the full contents (i.e., multiple fields) of the old-version
object $\oldvar$.  Transformers that are ruled out by this setup
include those that initialize field $f$ according to the
\emph{updated} value for field $f'$ as well as those that pass
values across the object graph, e.g., setting
\code{$\newvar.f_2$ := Foo.$f_1$} when $\oldvar$ is not an instance
of \code{Foo}.
% SBM: n.f2.f3 := o.f1 is okay.  I corrected to say what I think we
% originally meant here.
% as well as those that pass values across the object graph,
% e.g., using the value in $\oldvar.f_1$ when updating field
% $\newvar.f_2.f_3$.

\begin{figure}
\small
\[
\begin{array}{l@{}rcl}
\text{Updates} & \delta & \bnfas & \lambda \oldvar.\ \anew \newvar;\
g_1;\ \ldots;\ g_n; \return\ n\\
\text{Field Updates} & g & \bnfas & n.f := c \\
\text{Field Path} & f & \bnfas & \epsilon \mid f.l \\
\text{Conditional} & c & \bnfas & \casestart e_1 \carrow d_1, \ldots, e_n \carrow d_n \caseend \\
\text{Initializer} & d & \bnfas & k \mid \oldvar.f \mid \sconcat(\se_1,\ldots,\se_n) \\
& & & \mid \map(\delta, \oldvar.f) \\
\text{Integer Constant} & i, j & \in & \mathbb{Z} \\
\text{Constant} & k & \bnfas & i \mid \texttt{null} \mid \delim \\
\text{Delimiter} & \delim & \bnfas & \texttt{\textbackslash} \mid \texttt{/} \mid \texttt{\#} \mid \texttt{@} \mid \texttt{:} \\
\text{String Expression} & \se & \bnfas & \delim \mid \substr(\oldvar.f,i)\\
\text{Boolean Expression} & e & \bnfas & a \mid e_1 \wedge e_2 \mid e_1 \vee e_2 \\
\text{Atomic Expression} & a & \bnfas & \oldvar.f_1 \op \oldvar.f_2 \mid \oldvar.f \op k \\
\text{Operator} & \op & \bnfas & \mathord{=} \mid \mathord{\neq} \mid \ldots
\end{array}
\]
\caption{\label{fig:language}The language over which we perform synthesis.}
\end{figure}

\subsection{Synthesis algorithm}

\begin{figure}
\hspace*{.05in}
\begin{minipage}{4.3in}
\begin{lstlisting}[numbers=left]
synthesize($U$) =
  for each $\textsf{new-version}$ field $f_i$ { /**\label{line:path1}*/
    not_covered := $U$
    update_fns := []
    while not_covered $\neq$ $\emptyset$ { /**\label{line:not-covered-loop}*/
      choose $(o,o') \in$ not_covered
      let $D$ = synth_field($f_i$,$o$,$o'$)
      letfun score($d$) =
               $\setsize{\{(o,o') \mid (o,o') \in \textsf{not\_covered} \wedge o'.f_i = d(o)\}}$
      let $\hat{d}$ be the element of $D$ that maximizes score /**\label{line:maxscored}*/
      let $\hat{U} = \{(o,o') \mid (o,o') \in \textsf{not\_covered} \wedge o'.f_i = \hat{d}(o)\}$
      update_fns := update_fns $\concat (\hat{d},\hat{U})$
      not_covered := not_covered - $\hat{U}$
    }
    cond := []
    for i $\in$ 1..$\lstlength{\text{update\_fns}}$ { /**\label{line:discover-condition-loop}*/
      let $(\hat{d},\hat{U}) =$ update_fns(i)
      let ${\inset}$ = $\{o \mid \exists o'.\ (o,o') \in U \wedge (o,o') \in \hat{U}\}$
      let ${\outset}$ = $\{o \mid \exists o'.\ (o,o') \in U \wedge (o,o') \not\in \hat{U}\}$
      cond := cond $\concat$ (synth_cond(${\inset}$,${\outset}$))
    }
    $c_{f_i}$ := $\langle\,\casestart \hat{c}_1 \carrow \hat{d}_1, \ldots, \hat{c}_n \carrow \hat{d}_n \caseend\,\rangle$
      where $\hat{c}_j =$ cond(j) and $(\hat{d}_j,\hat{U}_j) =$ update_fns(j)
  }
  return $\langle\,\lambda \oldvar.\ \anew \newvar;\; \newvar.f_1 := c_{f_1};\ \ldots;\ \newvar.f_n := c_{f_n};\ \return\ \newvar\rangle$
\end{lstlisting}
\end{minipage}
\caption{Main synthesis algorithm.\label{fig:synthesis}}
\end{figure}

Figure \ref{fig:synthesis} gives pseudo-code for the synthesis
algorithm.  The main function is \textsf{synthesize}.  It takes a
set of input-output examples $U$ (pairs of old-version, new-version objects)
and produces a transformation function that
is consistent with those examples.

Synthesis proceeds one field at a time.  For each field,  it synthesizes a
conditional update ($c$ in the grammar in Figure \ref{fig:language}) that
is capable of producing all the values for that field seen in the example
pairs in $U$.  It first generates the initializers $d$ and then
searches for conditions that indicate which $d$ to apply.

To find the initializers $d$, the synthesis algorithm maintains a set \textsf{update\_fns} of
initializers it has discovered thus far, as well as
a set \textsf{not\_covered} that contains all example pairs that cannot
be produced by an initializer in \textsf{update\_fns}.  During each iteration
through the loop on line \ref{line:not-covered-loop}, it chooses an
element from \textsf{not\_covered} and calls \textsf{synth\_field},
which returns the set $D$ of all initializers $d$ that are
consistent with that field's values in the provided example pair.
Of these, we choose $\hat{d}$, which covers the largest number of
pairs in \textsf{not\_covered}, and add it to \textsf{update\_fns},
while removing the pairs that $\hat{d}$ covers from \textsf{not\_covered}.

The loop on line \ref{line:discover-condition-loop} finds the conditions that indicate which $\hat{d}$ to apply to a given old-version
object.
For each transformation function $\hat{d}$, the loop builds ${\inset}$,
containing the old-version objects from the example pairs 
consistent with $\hat{d}$, and ${\outset}$, containing the remaining example pairs.
It then calls \textsf{synth\_cond} to find a condition that separates these two
sets based on values of old-version fields, and adds it to the list \code{cond}.

Finally, the algorithm constructs $c_{f_i}$, the conditional update containing all the
logic it just synthesized for field $f_i$.  The update for the class is then
the sequence of all these field updates.  We write synthesized code in
angle brackets to distinguish it from the code of the synthesis
algorithm.

\subsection{Field synthesis}
\label{sec:field-synth}

Figure \ref{fig:non-branch-synthesis} gives the pseudo-code for
\textsf{synth\_field}, which produces the initializers for a
new-version field according to a given example pair.
The figure also shows the code for \textsf{synth\_non\_branching},
which is the function used to perform synthesis-based matching
(Section \ref{sec:synth-match}). It uses \textsf{synth\_field} as a
subroutine.

The \textsf{synth\_field} function takes a field, an old-version
object $o$, and a new-version object $o'$, and returns a set of initializers
(from production $d$ in the grammar in Figure \ref{fig:language}), where
each initializer can produce the value in $o'.f$ given the object $o$.
The set is constructed by first checking whether the value in $o'.f$
is also present in a field in $o$ and if its value can be copied over.
Next, it checks whether $o'.f$ is one of the constants in the synthesis language.
If so, it adds this production method to the returned set.
Finally, we have two class-based synthesis checks.  If $o'.f$ is a string,
we invoke string synthesis to produce a set that describes all possible
methods for construction the string from substrings present in $o$.
We do not give code for this function since it closely follows
Gulwani~\cite{Gulwani:popl:2011}.  If $o'.f$ is a collection, then we 
recursively invoke synthesis in order to transform the elements of the
collection.

\begin{figure}
\hspace*{.2in}
\begin{minipage}{4.3in}
\begin{lstlisting}[numbers=left]
synth_non_branching($o$,$o'$) =
  g := empty field update
  for each $f$ in $o'$ {
    let c_set = synth_field($f$,$o$,$o'$)
    for each $c \in $ c_set do { g := g + $\langle$ ; $\newvar.f$ := $c$ $\rangle$ }
  }
  return $\lambda \oldvar.\ \anew \newvar;\; \langle \text{g} \rangle; \return\ \newvar$

synth_field($f$,$o$,$o'$) =
  ret_set := $\emptyset$
  if $o'.f = o.g$ for some field $g$ /**\label{line:path2}*/
    ret_set := ret_set $\cup$ $\{\langle\,\oldvar.g\rangle\}$
  if $o'.f = k$
    ret_set := ret_set $\cup$ $\{\langle\,k\rangle\}$
  if typeof($o'.f$) = String
    ret_set := ret_set $\cup$ string_synth($o.f$,$o'.f$)
  if $o'.f$ is a collection
    let $\set'$ = multiset of objects in collection $o'.f$
    for each collection-valued field $o.f_2$ {
      let $\set$ = multiset of objects in collection $o.f_2$
      let $\delta$ = collection_synth$(\set,\set')$
      ret_set := ret_set $\cup$ {$\langle\map(\delta, o.f_2)\rangle$}
    }
  return ret_set

collection_synth($\set$,$\set'$) =
  let examples = match([$\set$],[$\set'$])
  return synthesize(examples)
\end{lstlisting}
\end{minipage}
\caption{Non-branching and per-field synth. subroutines.\label{fig:non-branch-synthesis}}
\end{figure}

\subsection{Condition synthesis}

Condition synthesis produces a condition that distinguishes two
sets of examples following the basic approach of
Gulwani~\cite{Gulwani:popl:2011}.  
Figure~\ref{fig:cond-synthesis} gives the pseudocode.  It uses notation
$\sembrack{e}$ to denote a function from objects to truth values where
$\sembrack{e}o = \true$ if and only if condition $e$ is true when
$o$ (an actual object) is substituted for $\oldvar$ (the variable) in
$e$.  If $\sembrack{e}o = \true$, we will say that $e$
\emph{includes} $o$ and otherwise we say that $e$ \emph{excludes}
$o$.  Given a set of objects $\inset$ and $\outset$, the goal of
condition synthesis is to return an expression $e$ such that $\forall o \in \inset\ 
\sembrack{e}o = \true$ and $\forall o \in
\outset\ \sembrack{e}o = \false$.  If this is the case, we say that
$e$ \emph{separates} $\inset$ and $\outset$.

The construction of $e$ proceeds in a greedy fashion.  The loop at
line~\ref{line:cond-outer} calls \code{synth_conj} to
synthesize a conjunction $a_1 \wedge \ldots \wedge a_n$, where each
$a_i$ is an atomic expression.  This expression will exclude all the elements in
$\outset$ while including as many elements of $\inset$ as possible.
The \code{synth_conj} function builds up this conjunction iteratively
using the loop at line~\ref{line:cond-inner}.
Given $e = a_1 \wedge \ldots \wedge a_j$, we first check to see if $e$
already separates $\inset$ and $\outset$.  If so, we are done---the
code detects this case when $\outset' = \emptyset$.  If not, let $\inset' =
\{o \mid o \in \inset \wedge \sembrack{e}o = \true\}$ and let
$\outset' = \{o \mid o \in \outset \wedge \sembrack{e}o = \true\}$.
Thus $\inset'$ and $\outset'$ are the subsets of $\inset$ and
$\outset$ that satisfy $e$.  We then choose $a_{j+1}$ to be the atomic
expression that maximizes $\rank{a_{j+1}}{\inset'}{\outset'}$.  We
define the \emph{rank} of a condition $e$ as follows.
\begin{defn}
Let $\rank{e}{\inset}{\outset} = m \times n$ where $m = \setsize{\{o
  \mid o \in \inset \wedge \sembrack{e}o = \true\}}$ and $n =
\setsize{\{o \mid o \in \outset \wedge \sembrack{e}o = \false\}}$.
\end{defn}
Thus, $\rank{e}{\inset}{\outset}$ is the product of the number of
objects from $\inset$ that are included by $e$ and the number of
objects in $\outset$ that are excluded.

The atomic expressions we consider are those involving equality or
inequality between pairs of fields (of which there are a finite
number) and equality or inequality with a constant appearing in the
object (of which there are a finite number).  Since there are a finite
number of possible atomic expressions, we can simply iterate over
them, although our implementation is able to avoid considering many
expressions that are guaranteed to not satisfy the conditions
required.  Provided
$\rank{a}{\inset'}{\outset'}$ is non-zero, we know that
conjoining $a$ to $e$ will cause some elements of $\outset'$ to be
excluded, while still including some elements of $\inset$.
If no atomic expression produces a rank greater than zero, then
this indicates a failure to find the necessary condition and we abort
the synthesis process for this field.  In this case our expression
language is either insufficient to distinguish the different examples,
or we have simply not considered the discriminating data (e.g., if it
were a global variable).  Otherwise we continue adding atomic
expressions until we have excluded all 
elements of $\outset$ and constructed conjunct $e$.

Returning to the code of \textsf{synth\_cond}, we know that the
conjunct returned from \textsf{synth\_conj} excludes all elements of $\outset$.
We add $e'$ to the current list of disjuncts $e$, and then
add to $\inset'$ the set $\{o \mid o \in \inset \wedge \sembrack{e'}o =
\true\}$, which are all objects $e$ now includes.  If any elements
remain, we iterate again to produce another conjunct that will include
them, until the expression includes all elements of
$\inset$ (and excludes all elements of $\outset$).

\begin{figure}
\hspace*{.2in}
\begin{minipage}{4.3in}
\begin{lstlisting}[numbers=left]
synth_cond($\inset$,$\outset$) =
  $\inset' := \emptyset$
  $e := \langle\false\rangle$
  while $\inset' \neq \inset$ { /**\label{line:cond-outer}*/
    let $e'$ = synth_conj($\inset - \inset'$,$\outset$)
    $e$ := $e$ + $\langle\;\vee\, e' \rangle$
    $\inset' := \inset' \cup \{o \mid o \in \inset \wedge \sembrack{e'}o = \true\}$
  }
  return $e$

synth_conj($\inset$,$\outset$) =
  $\inset' := \inset$
  $\outset' := \outset$
  $e$ := $\langle\true\rangle$
  while $\outset' \neq \emptyset$ {  /**\label{line:cond-inner}*/
    let $a$ be the condition that maximizes $\rank{a}{\inset'}{\outset'}$ /**\label{line:maxrank}*/
    if $\rank{a}{\inset'}{\outset'} = 0$ then abort
    $e$ := $e$ + $\langle\;\wedge\, a \rangle$
    $\inset'$ := $\{o \mid o \in \inset' \wedge \sembrack{e}o = \true\}$
    $\outset'$ := $\{o \mid o \in \outset' \wedge \sembrack{e}o = \true\}$
  }
  return $e$
\end{lstlisting}
\end{minipage}
\caption{Synthesizing conditions.\label{fig:cond-synthesis}}
\end{figure}

\subsection{Discussion}
\label{sec:synth-discuss}

Our synthesis algorithm is engineered to favor simpler, more general
transformations $\delta$ over more specialized ones.  For example,
suppose class \code{Foo} contains an integer-valued field \textsf{f}
and in all our snapshots $\set \in \setlst_{old}$ we have two
\code{Foo} objects $o_1$ and $o_2$ such that $o_1.f = 1$ and $o_2.f = 2$.  Likewise, all
snapshots $\set' \in \setlst_{new}$ have two \code{Foo} objects $o'_1$ and
$o'_2$ such that $o'_1.f = 1$ and $o'_2.f = 2$.  In this case,
\code{synthesize} will produce the function $$\lambda \oldvar. \anew
\newvar;\, \casestart \true \carrow \newvar.f := \oldvar.f \caseend;
\return\ \newvar$$ and not the function 
$$\begin{array}{r@{~~}l}
\lambda \oldvar. \anew \newvar; \casestart (\oldvar.f = 1) &\carrow \newvar.f := 1,\\
\casestart (\oldvar.f = 2) &\carrow \newvar.f := 2\caseend; \return\ \newvar
\end{array}
$$
Line~\ref{line:maxscored} of \code{synthesize}
(Figure~\ref{fig:synthesis}) favors initializers that apply to the
most possible objects.  Line~\ref{line:maxrank} of \code{synth_conj}
(Figure~\ref{fig:cond-synthesis}) similarly aims for simpler, more
general conditions.

The algorithm as described assumes that synthesis takes place on a
per-object basis, one field at a time.  In fact, it can also
synthesize the contents of a new object's children, e.g., assigning
not just $\newvar.f := d$ but $\newvar.f_1.f_2 := d$ as well.
Likewise it can read children of old objects in initializers $d$.  To
support this extension, we simply consider field \emph{paths} rather
than fields, up to a specified depth, e.g., on line~\ref{line:path1}
in Figure~\ref{fig:synthesis} and on line~\ref{line:path2} in
Figure~\ref{fig:non-branch-synthesis}.  Matching can be similarly
extended, e.g., using paths on line~\ref{line:firstloop} in
Figure~\ref{fig:matching-alg}.  Finally, we extend the synthesis
language in Figure~\ref{fig:language} to allow object allocation, so we can
allocate and initialize child objects if needed.  (Note that
allocation happens implicitly with $\map$ when producing the new
collection.)  We have found this flexibility useful in practice, as we
discuss in the Azureus example in the next section.

\section{Evaluation}
\label{sec:experiments}

We implemented \TOS and used it to synthesize object
transformers for several program updates we gathered from the wild.  
We choose challenging examples that other
systems cannot handle, and find that \TOS handles most.  \TOS does
fail when the changed objects do not store data
that makes it possible to match them between heaps, but this case is
less common.
This section provides a few more details about our implementation,
describes each test program update, and
our experiences with \TOS in each case.

\subsection{Implementation}

We use the Oracle HotSpot JVM to collect heap snapshots using the
\texttt{agentlib:hprof} command line option.\footnote{We use HotSpot
  only for snapshotting---Jvolve, the VM that \TOS targets, is based
  on Jikes RVM and does not support snapshotting.}
 This option invokes the
heap profiler, which sends the current snapshot over a
network socket.  We wrote a small server that coordinates snapshots
with the application. It initiates snapshots at update points and saves them
to disk.  In particular, when the application
reaches an update point, it calls into a helper class to trigger a
snapshot. % (rather than actually performing the dynamic update).
%% \footnote{A simpler approach to heap dumping is to use the command
%%   line tool \texttt{jmap}, which is provided with the Oracle Java VM.
%%   However, we were unable to get \texttt{jmap} to include string
%%   constants in the heap dump, forcing the use of the alternative
%%   approach described above.}

%% We produced a small helper class that can be linked into a program for
%% which we want to infer state update functions.  This class has a
%% static method that can be called in order to mark an update point.  In
%% a dynamic update scenario, this call would trigger a change in the
%% running version of the program.  In our update inference scenario,
%% this call triggers a snapshot and continues executing the program at
%% the current version.  This allows snapshots to be collected at all
%% possible update points in a single-version execution.

\TOS is implemented in Java and comprises roughly 4200 lines
of code. About 1300 lines implement matching, 1600 implement
synthesis, and the rest is common code.

%Non-determinism at the object level also causes problems for our
%synthesis approach

% \mwh{Would also be good to talk about how things didn't work.  Suriya
%   says: short-lived objects missed by snapshots, live and die between
%   snapshots.  Heavy nondeterminism (violating assumption given
%   earlier).  Leak: couldn't reproduce it which means you can't
%   synthesize the transformer since you can't observe it.}


\input{experiments}

\section{Related work}

This paper contributes novel matching and synthesis algorithms. The
matching algorithm analyzes unstructured heap snapshots from different
program version executions.  While some recent prior work analyzes a
single heap to discover leaked objects and other
inefficiencies~\cite{BM:06,BM:09,JM:07,MS:03,MS:07,XR:10}, none aligns
heap objects from different program versions or considers how to
fix the effects of leaks on the fly.

A lot of related work considers synthesizing code from specifications,
but only recently have researchers considered the problem of
synthesizing data transformation functions.  The closest related work
is by Gulwani and others on synthesizing string and Excel spreadsheet
data transformations.  These approaches require users to directly
specify the input/output examples whereas \TOS requires users to run
the same test on both program versions from which examples are
inferred by matching.  
Gulwani's
algorithm~\cite{Gulwani:popl:2011} synthesizes string functions that
include concatenation, subsequence, and finding special symbols.  \TOS
uses this algorithm as a subroutine as part of synthesizing
transformations between objects (cf. Section~\ref{sec:field-synth}).
Harris and Gulwani~\cite{Gulwani:pldi:2011} generate transformations
between spreadsheets; their numeric transformations and filters are
similar to ours.  They also search structured spreadsheet data to find
correlation between the input and output rows and columns. Our
matching phase serves a similar purpose, but once objects are paired
up, synthesis follows the structure of the new-version object,
assigning its fields one at a time.  
A unique feature of \TOS is that it iterates synthesis and matching to produce
transformers for collections of objects.

% They
% exploit the structure of the spreadsheets, whereas \TOS finds
% correlations in unstructured data by exploiting the Java static type
% system. \mwh{I don't get this last line}

% \mwh{Reviewer comment: - Could you phrase the problem of finding key-fields
% (distinguishing attributes) as a standard classification problem
% and use a standard algorithm for solving it?}

Many prior dynamic updating systems, including
Ginseng~\cite{neamtiu06dsu}, DLpop~\cite{HicksNettles03},
POLUS~\cite{chen:icse07}, and Jvolve~\cite{jvolve}, provide primitive
support for generating state transformation code.  For changes that
extend classes or structs with new fields, these systems
simply copy the old fields and initialize the new ones with default
values, e.g., \code{null} for object references, or 0 for
\code{int}\hspace{-0.5em}s.  Systems that provide no direct support for state
transformation, e.g., LiveRebel~\cite{javarebel}, effectively take
this approach.  In all of these cases, synthesis is based entirely on
comparing the definitions of changed types/classes.  None of them
consider program semantics by analyzing the code or the heap.  By contrast,
\TOS obtains semantic information from program execution to derive
data transformations.
%  runs, which allows it to infer
% transformation functions more reliably, while still being able to
% infer functions handled by prior systems.  
% \TOS also infers
% functions for objects whose type has not changed, but whose data is
% used in a different manner. 
In short, while prior systems remove some of the tedium of writing
transformation functions, they fail to handle any interesting program
changes, which are exactly the cases which are harder
for programmers to write correctly.

% \mwh{Here we can talk about Gulwani's work on synthesis for string
% programs, since we are using that basic approach.}  We have two
% contributions above what was done there.

% First, the effectiveness of the approach is highly dependent on the
% language used for synthesis.  You essentially want a domain-specific
% language with a good tradeoff between number of constructs and
% expressiveness.  Sumit mentions several times in his paper that it
% took some time to discover the right language for synthesis of string
% programs.  We are performing this very important task for the domain
% of Java object transformations (tailored to the dynamic update
% scenario).

% Second, in Sumit's work, input-output examples were provided by the
% user.  In our work, they must be discovered by analyzing the
% old-version and new-version heap.  We are contributing techniques to
% enable this matching process.

% When doing both of these, we get some advantages by working with Java.
% First, full type information is available at run-time.  Second, the
% fact that most programs make heavy use of Java's standard library
% helps, as it provides more high-level information.  Both these help
% with the matching problem.  For example, we can view a collection as a
% group of objects rather than a low-level pointer structure.  We can
% also use the fact that order is probably important for a List, but not
% important for a Set.

% \mwh{old text below, we might fold into this}


% Our synthesis approach is inspired by that in
% \cite{Gulwani:popl:2011}.  There are two crucial differences.
% First, our domain differs from that considered in
% \cite{Gulwani:popl:2011}, which performed synthesis of string
% transformations.  In our work, we are interested in synthesis of Java
% object transformers.  Java objects have a richer structure than
% strings, as they consist of a set of named fields which can be
% string-valued, integer-valued, etc. or which could refer to other
% objects or to collections of objects.  Performing synthesis over this
% richer domain necessitated the development of a core language for
% describing object updates.  As noted in \cite{Gulwani:popl:2011},
% the choice of which constructs to include in the language over which
% synthesis is performed is crucial to accuracy and efficiency of the
% algorithm.  Furthermore, because object fields can refer to other
% objects, we must perform the synthesis recursively.  This arises
% in particular when synthesizing updates for collections, which
% potentially involve both a transformation on the collection itself
% (for example a conversion from a LinkedList to an ArrayList) and a
% transformation on the elements of the collection (which may themselves
% be collections).

% The second difference is that in \cite{Gulwani:popl:2011}, the
% input-output examples are provided by the user, whereas in our current
% work, the input-output pairs must be inferred.  \stephen{Could cut
%   here and move the text below to an overview section.}  We adopt a
% three-stage approach to handle this.  The first stage is \emph{data
%   collection}.  We start with old and new versions of the program,
% with the update location marked.  Prior work has shown that a small
% number of fixed update points is generally sufficient to ensure that
% updates are applied quickly~\cite{hayden11testing-journal}.  To collect data on
% how objects change between versions, we run the old and new versions
% of the program over the same high-level input.  As the programs run,
% we dump the heap each time an update point is encountered.  We require
% that the update points in the old and new version match.  For example,
% there might be a single update point at the beginning of the main
% event loop in both versions.  This gives us a series of snapshots of
% the heap for each version.  Our goal is then to use these snapshots to
% infer a function that maps each old-version heap to the corresponding
% new-version heap.


%In effect, we are attempting to infer some semantic information that
%is not present in the text of the program.  We do this by running the
%code repeatedly and examining the objects produced.

\section{Conclusions}

% KSM: done. \stephencomment{Mention that the procedure fails when it should and gives good diagnostic info}


This paper has presented \TOSAcronym, a novel technique that
synthesizes \emph{object transformer methods}. Object transformers
convert old version objects to new ones during a dynamic software
update.  \TOS is distinguished by its generality: whereas prior
techniques for synthesizing object transformers follow simple
syntactic rules, \TOS produces functions based on observations of
actual program executions of the old and new program versions.  In
particular, \TOS takes periodic heap snapshots at corresponding points
during executions of the old and new program when executing the
same inputs.  It then \emph{matches} corresponding objects between
these snapshots, and uses these as examples to \emph{synthesize}
object transformation functions.  We show \TOS is efficacious in
synthesizing transformation functions for actual changes to classes in
various Java server applications. Even when it fails to generate a
correct transformer, the partial results may be useful to
developers.  This functionality eases, but does not eliminate, the
programmer burden of understanding program changes and performing
dynamic software updating.  \TOS may also be useful for other version and
program understanding scenarios, such as bug detection
and testing.

\paragraph*{Acknowledgments} 

We thank the anonymous reviewers for helpful comments on drafts of
this paper.  This work is supported by NSF grants CCF-0910530,
CCF-1018271 and SHF-0910818 and the
partnership between UMIACS and the Laboratory for Telecommunication
Sciences.  Any opinions, findings and conclusions expressed herein are
the authors' and do not necessarily reflect those of the sponsors.


\bibliographystyle{abbrvnat}
\balance
% \renewcommand{\bibfont}{\footnotesize} % <--- change bib font size here
% \setlength{\bibsep}{0.5ex}             % <--- change space between bib entries here
\bibliography{biblio}

%% \section{OLD TEXT}

%% The example from Figure
%% \ref{fig:leak-1-state-update} illustrates both these concepts.  The
%% transformation function assigns \texttt{null} to
%% \texttt{new.\_server.adapter}, but only if
%% \texttt{old.\_server.\_bContinue} is true.  This function could not be
%% produced by starting with \texttt{\_server.adapter}.  It is critical
%% that the synthesis code had access to the
%% \texttt{\_server.\_bContinue} field.

%\input oldtext

\end{document}
